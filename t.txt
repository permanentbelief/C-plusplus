网络基础 

http与https：
 
 1. 通信过程容易被劫持，因此通过数据加密进行保护
 分为 对称加密 非对称加密
 2. 如果通信过程中一直采用对称加密算法，很容易被破解
 3. 因此最好采用非对称加密算法，但是非对称加密算法解析的性能比较低
 4. 因此更进一步： 采用动态协商对称加密算法，协商的过程采用非对称加密算法进行加密
 5. 非对称加密算法由 服务端生成一个公钥，然后获取CA颁发的整数和私钥，将公钥发给对方，对方用公钥加密，
 自己用私钥解密
 6. 因为公钥容易被劫持，所以用签名证书的方式证明身份，防止证书被劫持，因此需要权威机构办法


udp面向数据报
1. 特性取决于udp数据报长度这个字段  uint16_t决定了udp整个数据报长度不能大于64k,若大于的话，两个字节就不够存了
2. 因为udp有数据报长度的限制，因此数据过大，则需要用户在应用层进行数据分包
3. udp并不保证数据的可靠，有序的到达，因此可能是乱序，需要用户在应用层进行包序管理
4. udp在sendto发送数据的时候将数据发送缓冲区，直接封装头部，将数据发送出去


为什么要做这个项目？(初衷)
让网络中的任意两台主机之间可以互相下载文件
 

设计的过程中就会包括两个大的模块：
1. 客户端模块： 查看共享主机 -> 获取主机文件列表 -> 从指定主机下载文件
2. 服务端模块：针对于客户端的请求提供客户端请求服务


一定范围内的定长内存池：
解决的问题： 性能问题 + 应用范围更广的问题  利用哈希映射关系
没有解决的问题： 内存碎片问题， 将内存切成很多个小块的内存，8字节的内存，
全部挂载自由链表的8字节对应的下面，所以当申请更大的内存时，就不能从内存中申请，
合并的过程中也很难合并，因为内存是连续的，归还的时候也要将内存前后的页进行合并。

malloc解决的是 性能问题 + 内存碎片(系统提供的级别)
未解决的是 ： 并发的malloc

内存碎片是 ： 
将大内存切成小内存了，使得没有剩余的空间可以申请了，所以要进行合并。
所以 要以 页 为单位合并

Span:
{
	pageid; //页号
	free_list; // 自由链表
	use_count; // 使用计数
}

page cache以页为单位 申请内存，那么一次申请几页呢？
没 不到一页就给1页， 不超过2页 就给2页
以一个span的方式 给你，会告诉你这个页的页号，知道页号就知道这块空间的地址






